# -*- coding: utf-8 -*-
from DrissionPage import ChromiumPage, ChromiumOptions
import pandas as pd
import time
import random
import os
from urllib.parse import urljoin

# ================= é…ç½®åŒºåŸŸ =================
TARGET_URL = "https://ningbo.chinatax.gov.cn/zcwj/zcfgk/index.html"
VERSION = "v10.0 (ç¨³å¦‚è€ç‹—ç‰ˆ - å¼ºåˆ¶ä¼‘çœ ç¿»é¡µ)"


def get_desktop_path():
    return os.path.join(os.path.expanduser("~"), "Desktop")


OUTPUT_FILE = os.path.join(get_desktop_path(), "å®æ³¢ç¨åŠ¡_æ”¿ç­–æ³•è§„åº“_å…¨é‡æŠ“å–.xlsx")


# ================= æ ¸å¿ƒé€»è¾‘ =================

def extract_detail(tab):
    try:
        info = {
            "æ­£æ–‡": "", "æ–‡å·": "", "å‘æ–‡å•ä½": "", "å‘å¸ƒæ—¥æœŸ": "", "é™„ä»¶": []
        }

        # 1. Meta
        try:
            date_ele = tab.ele('xpath://meta[@name="PubDate"]')
            if date_ele: info["å‘å¸ƒæ—¥æœŸ"] = date_ele.attr("content").split(" ")[0]
            source_ele = tab.ele('xpath://meta[@name="ContentSource"]')
            if source_ele: info["å‘æ–‡å•ä½"] = source_ele.attr("content")
        except:
            pass

        # 2. æ­£æ–‡
        content_ele = tab.ele('#zoom')
        if content_ele:
            info["æ­£æ–‡"] = content_ele.text
        else:
            info["æ­£æ–‡"] = tab.ele('.info-cont').text if tab.ele('.info-cont') else "æ­£æ–‡æå–å¤±è´¥"

        # 3. æ–‡å·
        if not info["æ–‡å·"]:
            first_part = info["æ­£æ–‡"][:300]
            if "å‘å¸ƒæ–‡å·" in first_part:
                try:
                    parts = first_part.split("å‘å¸ƒæ–‡å·")
                    candidate = parts[1].split("\n")[0].replace("ã€‘", "").replace(":", "").replace("ï¼š", "").strip()
                    info["æ–‡å·"] = candidate
                except:
                    pass

        # 4. é™„ä»¶
        links = tab.eles('tag:a')
        for link in links:
            href = link.attr('href')
            if not href: continue
            if href.endswith(('.doc', '.docx', '.xls', '.xlsx', '.pdf', '.zip', '.rar')):
                full_url = urljoin(tab.url, href)
                info["é™„ä»¶"].append({
                    "æ–‡ä»¶å": link.text,
                    "é“¾æ¥": full_url
                })
        return info

    except Exception as e:
        print(f"    âŒ è¯¦æƒ…é¡µè§£æå‡ºé”™: {e}")
        return {}


def save_to_excel(data_list, filepath):
    if not data_list: return
    while True:
        try:
            df_new = pd.DataFrame(data_list)
            if os.path.exists(filepath):
                try:
                    with pd.ExcelWriter(filepath, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:
                        pass
                    df_old = pd.read_excel(filepath, engine="openpyxl")
                    df = pd.concat([df_old, df_new], ignore_index=True)
                    df.drop_duplicates(subset=["é“¾æ¥", "é™„ä»¶é“¾æ¥"], keep="last", inplace=True)
                except PermissionError:
                    raise PermissionError
                except:
                    df = df_new
            else:
                df = df_new

            cols = ["æ ‡é¢˜", "å‘å¸ƒæ—¥æœŸ", "å‘æ–‡å•ä½", "æ–‡å·", "æ­£æ–‡", "é™„ä»¶æ–‡ä»¶å", "é™„ä»¶é“¾æ¥", "é“¾æ¥"]
            for c in cols:
                if c not in df.columns: df[c] = ""
            df = df[cols]
            df.to_excel(filepath, index=False, engine="openpyxl")
            print(f"   ğŸ’¾ å·²ä¿å­˜ (æ€»è¡Œæ•°: {len(df)})")
            break
        except PermissionError:
            print("\nğŸš¨ é”™è¯¯ï¼šExcel æ–‡ä»¶è¢«å ç”¨ï¼è¯·å…³é—­æ–‡ä»¶...")
            time.sleep(5)
        except Exception as e:
            print(f"   âŒ Excelä¿å­˜æœªçŸ¥å¤±è´¥: {e}")
            break


def main():
    print(f"ğŸš€ å¯åŠ¨é‡‡é›†å™¨ - {VERSION}")

    co = ChromiumOptions()
    co.set_user_agent(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    co.set_argument('--blink-settings=imagesEnabled=false')
    co.set_argument('--mute-audio')
    co.set_argument('--window-position=-3000,-3000')  # ç§»å‡ºå±å¹•
    co.ignore_certificate_errors()

    page = ChromiumPage(addr_or_opts=co)

    print(f"ğŸŒ æ­£åœ¨è®¿é—®: {TARGET_URL}")
    page.get(TARGET_URL)
    time.sleep(3)  # é¦–æ¬¡åŠ è½½å¤šç­‰ä¸€ä¼š

    processed_urls = set()
    if os.path.exists(OUTPUT_FILE):
        try:
            try:
                df = pd.read_excel(OUTPUT_FILE, engine="openpyxl")
                processed_urls = set(df["é“¾æ¥"].dropna().tolist())
                print(f"ğŸ“š å·²è¯»å– {len(processed_urls)} æ¡å†å²è®°å½•")
            except:
                pass
        except:
            pass

    page_num = 1
    empty_page_count = 0

    while True:
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {page_num} é¡µ...")

        # 1. æ‰«æé“¾æ¥ (v3.0 é£æ ¼)
        try:
            page.wait.ele('tag:a', timeout=10)
        except:
            pass

        all_links = page.eles('tag:a')
        article_links = []
        for link in all_links:
            url = link.attr('href')
            title = link.text

            if not url or "javascript" in url: continue
            if not title or len(title) < 5: continue

            # æ··åˆè¿‡æ»¤å™¨ï¼šæ˜¯æ–‡ç«  ä¸” ä¸æ˜¯åˆ†ç±»é¡µ
            is_article = ("/art/" in url) or ("/content/" in url) or ("202" in url)
            is_category = url.endswith("index.html")

            if is_article and not is_category:
                if url not in processed_urls:
                    article_links.append({"title": title, "url": url})

        unique_links = []
        seen = set()
        for item in article_links:
            if item['url'] not in seen:
                unique_links.append(item)
                seen.add(item['url'])

        if not unique_links:
            print("âš ï¸ æœ¬é¡µæœªå‘ç°æ–°æ•°æ®ã€‚")
            empty_page_count += 1
            if empty_page_count >= 3:
                print("ğŸ›‘ è¿ç»­ 3 é¡µæ— æ•°æ®ï¼Œåˆ¤æ–­ä¸ºç»“æŸã€‚")
                break
        else:
            print(f"   ğŸ“„ ç­›é€‰å‡º {len(unique_links)} ç¯‡æ–°æ–‡ç« ")
            empty_page_count = 0

        # 2. æŠ“å–
        for item in unique_links:
            print(f"   Downloading: {item['title'][:15]}...")
            try:
                new_tab = page.new_tab(item["url"])
                new_tab.ele('#zoom', timeout=8)

                detail = extract_detail(new_tab)
                new_tab.close()

                row_base = {
                    "æ ‡é¢˜": item["title"],
                    "é“¾æ¥": item["url"],
                    "å‘å¸ƒæ—¥æœŸ": detail.get("å‘å¸ƒæ—¥æœŸ", ""),
                    "å‘æ–‡å•ä½": detail.get("å‘æ–‡å•ä½", ""),
                    "æ–‡å·": detail.get("æ–‡å·", ""),
                    "æ­£æ–‡": detail.get("æ­£æ–‡", "")
                }

                current_data = []
                if detail["é™„ä»¶"]:
                    for att in detail["é™„ä»¶"]:
                        row = row_base.copy()
                        row["é™„ä»¶æ–‡ä»¶å"] = att["æ–‡ä»¶å"]
                        row["é™„ä»¶é“¾æ¥"] = att["é“¾æ¥"]
                        current_data.append(row)
                else:
                    row_base["é™„ä»¶æ–‡ä»¶å"] = ""
                    row_base["é™„ä»¶é“¾æ¥"] = ""
                    current_data.append(row_base)

                processed_urls.add(item["url"])
                save_to_excel(current_data, OUTPUT_FILE)
                time.sleep(0.05)
            except Exception as e:
                print(f"   âŒ: {e}")
                if page.tabs_count > 1: page.close_tabs(page.tab_ids[1:])

                # 3. ç¿»é¡µ (v10.0: å‚»ç“œå¼å¼ºåˆ¶ä¼‘çœ )
        print("ğŸ‘† ç¿»é¡µä¸­...")
        try:
            # é”å®šå³ä¾§
            right_box = page.ele('.right-box')
            if right_box:
                next_btn = right_box.ele('.layui-laypage-next')
            else:
                next_btn = page.ele('.layui-laypage-next')

            if next_btn:
                # æ£€æŸ¥ç¦ç”¨
                class_val = next_btn.attr("class")
                if class_val and "disabled" in class_val:
                    print(f"ğŸ›‘ æŒ‰é’®å˜ç°ï¼ŒæŠ“å–ç»“æŸ (å…± {page_num} é¡µ)")
                    break

                # ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ JS ç‚¹å‡» + å¼ºåˆ¶ä¼‘çœ 
                # è¿™ç§æ–¹å¼æœ€æ— è„‘ï¼Œä½†ä¹Ÿæœ€ç¨³
                next_btn.click(by_js=True)

                print("   â³ ç­‰å¾…é¡µé¢åˆ·æ–° (3ç§’)...")
                time.sleep(3)

                print("   âœ… å‡å®šç¿»é¡µæˆåŠŸï¼Œç»§ç»­ä¸‹ä¸€è½®")
                page_num += 1
            else:
                print("ğŸ›‘ æœªæ‰¾åˆ°ç¿»é¡µæŒ‰é’®ï¼Œç»“æŸã€‚")
                break

        except Exception as e:
            print(f"ğŸ›‘ ç¿»é¡µæµç¨‹å‡ºé”™: {e}")
            break

    print(f"\nğŸ‰ å®Œæˆï¼æ–‡ä»¶: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()